{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf73bcd",
   "metadata": {},
   "source": [
    "## Imports & Global Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8d3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import easyocr\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac4714",
   "metadata": {},
   "source": [
    "## GPU Optimizations (PyTorch / cuDNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4b6559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3937e67b",
   "metadata": {},
   "source": [
    "## OCR Reader Initialization (Digits Only, GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d7d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OCR_READER = easyocr.Reader(['en'], gpu=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ed2c3",
   "metadata": {},
   "source": [
    "## Debug Controls (Crop Saving for OCR Inspection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea09eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG_OCR = True\n",
    "DEBUG_SAVE_EVERY = 15     # save every N frames per track\n",
    "DEBUG_MAX_FRAMES = 900    # debug first N frames\n",
    "DEBUG_DIR = \"debug_ocr\"\n",
    "os.makedirs(DEBUG_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973dd233",
   "metadata": {},
   "source": [
    "## Core Settings & Persistence Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d05de6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "JERSEY_MODE = \"back\"      # \"back\" or \"front\"\n",
    "DEVICE_ID = 0             # cuda:0\n",
    "\n",
    "# Start loose then you can tighten later\n",
    "CONF_TH = 0.30\n",
    "MIN_READS = 5\n",
    "MAXLEN_READS = 140\n",
    "LOCK_MARGIN = 1.10\n",
    "\n",
    "# show number only if locked OR very strong single read\n",
    "SHOW_SINGLE_IF_CONF_GE = 0.60\n",
    "\n",
    "# Memory / Persistence\n",
    "FPS_ASSUMED = 30\n",
    "TTL_SECONDS = 3.0\n",
    "TTL_FRAMES = int(TTL_SECONDS * FPS_ASSUMED)\n",
    "\n",
    "track_numbers = defaultdict(list)  # track_id -> [(num, conf), ...]\n",
    "locked_number = {}                 # track_id -> locked number\n",
    "last_seen_frame = {}               # track_id -> last frame idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d0a72",
   "metadata": {},
   "source": [
    "### Grass Color Helper (BGR Mean of Green Mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5bb626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grass_color(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower_green = np.array([30, 40, 40])\n",
    "    upper_green = np.array([80, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    grass_color = cv2.mean(img, mask=mask)\n",
    "    return grass_color[:3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1830fb16",
   "metadata": {},
   "source": [
    "### Extract Player Crops from YOLO Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d95edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_players_boxes(result):\n",
    "    players_imgs = []\n",
    "    players_boxes = []\n",
    "    for box in result.boxes:\n",
    "        label = int(box.cls.cpu().numpy()[0])\n",
    "        if label == 0:  # person\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "            player_img = result.orig_img[y1:y2, x1:x2]\n",
    "            if player_img.size:\n",
    "                players_imgs.append(player_img)\n",
    "                players_boxes.append(box)\n",
    "    return players_imgs, players_boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d69e48e",
   "metadata": {},
   "source": [
    "### Compute Kit Color per Player (Upper Body, Grass Removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1709e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kits_colors(players, grass_hsv=None, frame=None):\n",
    "    kits_colors = []\n",
    "    if grass_hsv is None:\n",
    "        grass_color = get_grass_color(frame)\n",
    "        grass_hsv = cv2.cvtColor(np.uint8([[list(grass_color)]]), cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    for player_img in players:\n",
    "        hsv = cv2.cvtColor(player_img, cv2.COLOR_BGR2HSV)\n",
    "        lower_green = np.array([grass_hsv[0, 0, 0] - 10, 40, 40])\n",
    "        upper_green = np.array([grass_hsv[0, 0, 0] + 10, 255, 255])\n",
    "        mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "        mask = cv2.bitwise_not(mask)\n",
    "\n",
    "        upper_mask = np.zeros(player_img.shape[:2], np.uint8)\n",
    "        upper_mask[0:player_img.shape[0] // 2, :] = 255\n",
    "        mask = cv2.bitwise_and(mask, upper_mask)\n",
    "\n",
    "        kit_color = np.array(cv2.mean(player_img, mask=mask)[:3])\n",
    "        kits_colors.append(kit_color)\n",
    "\n",
    "    return kits_colors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae211c2b",
   "metadata": {},
   "source": [
    "### KMeans Kit Classifier (2 Teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "704a607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kits_classifier(kits_colors):\n",
    "    kits_kmeans = KMeans(n_clusters=2, n_init=\"auto\")\n",
    "    kits_kmeans.fit(kits_colors)\n",
    "    return kits_kmeans\n",
    "\n",
    "def classify_kits(kits_classifer, kits_colors):\n",
    "    return kits_classifer.predict(kits_colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233813f5",
   "metadata": {},
   "source": [
    "### Decide Which Cluster Is ‚ÄúLeft Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3382793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_left_team_label(players_boxes, kits_colors, kits_clf):\n",
    "    left_team_label = 0\n",
    "    team_0 = []\n",
    "    team_1 = []\n",
    "\n",
    "    for i in range(len(players_boxes)):\n",
    "        x1, y1, x2, y2 = map(int, players_boxes[i].xyxy[0].cpu().numpy())\n",
    "        team = classify_kits(kits_clf, [kits_colors[i]]).item()\n",
    "        (team_0 if team == 0 else team_1).append(np.array([x1]))\n",
    "\n",
    "    team_0 = np.array(team_0) if len(team_0) else np.array([0])\n",
    "    team_1 = np.array(team_1) if len(team_1) else np.array([0])\n",
    "\n",
    "    if np.average(team_0) - np.average(team_1) > 0:\n",
    "        left_team_label = 1\n",
    "    return left_team_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf7eea",
   "metadata": {},
   "source": [
    "### ROI Generator for Jersey Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d5f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jersey_rois(player_img_bgr, mode=\"back\"):\n",
    "    \"\"\"\n",
    "    Wider left margin to capture thin '1'\n",
    "    \"\"\"\n",
    "    h, w = player_img_bgr.shape[:2]\n",
    "    if h < 50 or w < 35:\n",
    "        return []\n",
    "\n",
    "    rois = []\n",
    "    if mode == \"back\":\n",
    "        rois.append(player_img_bgr[int(h*0.12):int(h*0.82), int(w*0.12):int(w*0.88)])\n",
    "        rois.append(player_img_bgr[int(h*0.18):int(h*0.78), int(w*0.18):int(w*0.82)])\n",
    "        rois.append(player_img_bgr[int(h*0.25):int(h*0.85), int(w*0.15):int(w*0.85)])\n",
    "    else:\n",
    "        rois.append(player_img_bgr[int(h*0.10):int(h*0.75), int(w*0.12):int(w*0.88)])\n",
    "        rois.append(player_img_bgr[int(h*0.16):int(h*0.70), int(w*0.18):int(w*0.82)])\n",
    "\n",
    "    return [r for r in rois if r is not None and r.size != 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfc1fc5",
   "metadata": {},
   "source": [
    "### Image Variants for OCR (Gentle Thresholding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3474c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_variants(roi_bgr):\n",
    "    \"\"\"\n",
    "    Gentle variants to avoid killing thin '1'\n",
    "    \"\"\"\n",
    "    if roi_bgr is None or roi_bgr.size == 0:\n",
    "        return []\n",
    "\n",
    "    roi = cv2.resize(roi_bgr, None, fx=2.8, fy=2.8, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    gray2 = clahe.apply(gray)\n",
    "\n",
    "    thr = cv2.threshold(gray2, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "    inv = cv2.bitwise_not(thr)\n",
    "\n",
    "    ada = cv2.adaptiveThreshold(gray2, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 21, 5)\n",
    "    ada_inv = cv2.bitwise_not(ada)\n",
    "\n",
    "    roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return [\n",
    "        (\"rgb\", roi_rgb),\n",
    "        (\"gray\", gray2),\n",
    "        (\"thr\", thr),\n",
    "        (\"inv\", inv),\n",
    "        (\"ada\", ada),\n",
    "        (\"ada_inv\", ada_inv),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43bc9a",
   "metadata": {},
   "source": [
    "### OCR Helpers (Digits Only + Best Candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c2f1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ocr_digits(img, allow=\"0123456789\"):\n",
    "    return OCR_READER.readtext(img, detail=1, paragraph=False, allowlist=allow)\n",
    "\n",
    "def _best_digits_from_results(results):\n",
    "    best_num, best_conf = None, 0.0\n",
    "    for bbox, text, conf in results:\n",
    "        digits = re.sub(r\"\\D\", \"\", text)\n",
    "        if 1 <= len(digits) <= 2:\n",
    "            conf = float(conf)\n",
    "            if conf > best_conf:\n",
    "                best_conf = conf\n",
    "                best_num = digits\n",
    "    return best_num, best_conf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba762e47",
   "metadata": {},
   "source": [
    "### Prefix ‚Äú1‚Äù Recovery (Fixes 14‚Üí4 Mistake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "334f293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _detect_prefix_one(roi_bgr):\n",
    "    \"\"\"\n",
    "    Detect digit '1' in a thin left strip.\n",
    "    \"\"\"\n",
    "    h, w = roi_bgr.shape[:2]\n",
    "    if h < 20 or w < 20:\n",
    "        return False, 0.0\n",
    "\n",
    "    strip = roi_bgr[:, :max(8, int(w * 0.28))]\n",
    "    for tag, img in make_variants(strip):\n",
    "        res = _ocr_digits(img, allow=\"1\")\n",
    "        for bbox, text, conf in res:\n",
    "            t = re.sub(r\"\\D\", \"\", text)\n",
    "            if t == \"1\" and float(conf) >= 0.25:\n",
    "                return True, float(conf)\n",
    "    return False, 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01ae0b",
   "metadata": {},
   "source": [
    "### Main Jersey Number Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6720dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_jersey_number(player_img_bgr, mode=\"back\"):\n",
    "    \"\"\"\n",
    "    Best-of multi-ROI + multi-variants\n",
    "    plus prefix-1 recovery (14->4 fix).\n",
    "    Returns (num, conf, tag)\n",
    "    \"\"\"\n",
    "    best_num, best_conf, best_tag = None, 0.0, None\n",
    "\n",
    "    rois = jersey_rois(player_img_bgr, mode=mode)\n",
    "    for roi in rois:\n",
    "        # normal 1-2 digit read\n",
    "        for tag, img in make_variants(roi):\n",
    "            results = _ocr_digits(img, allow=\"0123456789\")\n",
    "            num, conf = _best_digits_from_results(results)\n",
    "            if num is not None and conf > best_conf:\n",
    "                best_num, best_conf, best_tag = num, conf, tag\n",
    "\n",
    "        # If best is 1 digit, try to recover a missing leading '1'\n",
    "        if best_num is not None and len(best_num) == 1:\n",
    "            has1, c1 = _detect_prefix_one(roi)\n",
    "            if has1:\n",
    "                candidate = \"1\" + best_num\n",
    "                cand_conf = min(0.99, max(best_conf, 0.60))\n",
    "                if cand_conf >= best_conf:\n",
    "                    best_num, best_conf, best_tag = candidate, cand_conf, \"prefix1+\" + (best_tag or \"\")\n",
    "\n",
    "    return best_num, best_conf, best_tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9477bd",
   "metadata": {},
   "source": [
    "### Voting / Locking Logic (Per Track)\n",
    "##### Update History Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0014f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_track_number(track_id, num, conf, maxlen=MAXLEN_READS):\n",
    "    if track_id is None or num is None:\n",
    "        return\n",
    "    track_numbers[track_id].append((num, float(conf)))\n",
    "    if len(track_numbers[track_id]) > maxlen:\n",
    "        track_numbers[track_id] = track_numbers[track_id][-maxlen:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dd437e",
   "metadata": {},
   "source": [
    "### Get Stable Number by Score (freq √ó avg_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfb499a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stable_number(track_id, min_reads=MIN_READS, conf_th=CONF_TH, margin=LOCK_MARGIN):\n",
    "    if track_id is None:\n",
    "        return None\n",
    "\n",
    "    reads = track_numbers.get(track_id, [])\n",
    "    if len(reads) < min_reads:\n",
    "        return None\n",
    "\n",
    "    reads = [(n, c) for (n, c) in reads if c >= conf_th]\n",
    "    if len(reads) < 3:\n",
    "        return None\n",
    "\n",
    "    by_num = defaultdict(list)\n",
    "    for n, c in reads:\n",
    "        by_num[n].append(c)\n",
    "\n",
    "    scores = []\n",
    "    for n, confs in by_num.items():\n",
    "        freq = len(confs)\n",
    "        avgc = sum(confs) / len(confs)\n",
    "        score = freq * avgc\n",
    "        scores.append((score, n))\n",
    "\n",
    "    scores.sort(reverse=True)\n",
    "    best_score, best_num = scores[0]\n",
    "    second_score = scores[1][0] if len(scores) > 1 else 0.0\n",
    "\n",
    "    if second_score > 0 and (best_score / second_score) < margin:\n",
    "        return None\n",
    "\n",
    "    return best_num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8153a",
   "metadata": {},
   "source": [
    "### Lock Policy (Avoid locking 1-digit too early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9515e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_lock(track_id, stable_num, reads, prefer_two_digits=True):\n",
    "    \"\"\"\n",
    "    Do NOT lock single-digit easily (prevents 14 -> 4 lock).\n",
    "    \"\"\"\n",
    "    if stable_num is None:\n",
    "        return False\n",
    "\n",
    "    if prefer_two_digits and len(stable_num) == 1:\n",
    "        strong = [(n, c) for (n, c) in reads if n == stable_num and c >= 0.80]\n",
    "        return len(strong) >= 10  # very strict for 1-digit\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ea140",
   "metadata": {},
   "source": [
    "### Upgrade Policy (1-digit lock ‚Üí 2-digit if strong later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac8cb69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_upgrade_lock(track_id):\n",
    "    \"\"\"\n",
    "    If locked to 1-digit but a 2-digit becomes dominant later, upgrade.\n",
    "    \"\"\"\n",
    "    if track_id is None or track_id not in locked_number:\n",
    "        return\n",
    "\n",
    "    cur = locked_number[track_id]\n",
    "    reads = track_numbers.get(track_id, [])\n",
    "    if len(cur) == 1:\n",
    "        good2 = [n for (n, c) in reads if len(n) == 2 and c >= 0.55]\n",
    "        if len(good2) >= 5:\n",
    "            from collections import Counter\n",
    "            cand = Counter(good2).most_common(1)[0][0]\n",
    "            locked_number[track_id] = cand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd760403",
   "metadata": {},
   "source": [
    "### Cleanup Old Tracks (TTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63e7aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_old_tracks(frame_idx):\n",
    "    to_delete = []\n",
    "    for tid, last_f in list(last_seen_frame.items()):\n",
    "        if frame_idx - last_f > TTL_FRAMES:\n",
    "            to_delete.append(tid)\n",
    "\n",
    "    for tid in to_delete:\n",
    "        last_seen_frame.pop(tid, None)\n",
    "        locked_number.pop(tid, None)\n",
    "        track_numbers.pop(tid, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6881d1",
   "metadata": {},
   "source": [
    "### üé¨ Main Pipeline: Track + Team Classify + OCR + Render\n",
    "#### Video Annotation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bfb2da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_video(video_path, model):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"ERROR: Could not open video: {video_path}\")\n",
    "        return\n",
    "\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    video_name = video_path.split('/')[-1]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_video = cv2.VideoWriter(\n",
    "        './output/' + video_name.split('.')[0] + \"_out.mp4\",\n",
    "        fourcc,\n",
    "        30.0,\n",
    "        (width, height)\n",
    "    )\n",
    "\n",
    "    kits_clf = None\n",
    "    left_team_label = 0\n",
    "    grass_hsv = None\n",
    "\n",
    "    pbar = tqdm(total=total_frames, unit=\"frame\", desc=\"Annotating video\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        frame_idx = int(cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
    "        pbar.update(1)\n",
    "\n",
    "        annotated_frame = cv2.resize(frame, (width, height))\n",
    "\n",
    "        # tracking (try botsort)\n",
    "        try:\n",
    "            result = model.track(\n",
    "                annotated_frame,\n",
    "                conf=0.5,\n",
    "                persist=True,\n",
    "                verbose=False,\n",
    "                device=DEVICE_ID,\n",
    "                tracker=\"botsort.yaml\"\n",
    "            )[0]\n",
    "        except Exception:\n",
    "            result = model.track(\n",
    "                annotated_frame,\n",
    "                conf=0.5,\n",
    "                persist=True,\n",
    "                verbose=False,\n",
    "                device=DEVICE_ID\n",
    "            )[0]\n",
    "\n",
    "        # Team clustering init\n",
    "        players_imgs, players_boxes = get_players_boxes(result)\n",
    "        kits_colors = get_kits_colors(players_imgs, grass_hsv, annotated_frame)\n",
    "\n",
    "        if kits_clf is None and len(kits_colors) >= 2:\n",
    "            kits_clf = get_kits_classifier(kits_colors)\n",
    "            left_team_label = get_left_team_label(players_boxes, kits_colors, kits_clf)\n",
    "            grass_color = get_grass_color(result.orig_img)\n",
    "            grass_hsv = cv2.cvtColor(np.uint8([[list(grass_color)]]), cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        for box in result.boxes:\n",
    "            label = int(box.cls.cpu().numpy()[0])\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())\n",
    "\n",
    "            track_id = None\n",
    "            if hasattr(box, \"id\") and box.id is not None:\n",
    "                track_id = int(box.id.cpu().numpy()[0])\n",
    "\n",
    "            if track_id is not None:\n",
    "                last_seen_frame[track_id] = frame_idx\n",
    "\n",
    "            jersey_text = None\n",
    "            debug_info = None\n",
    "\n",
    "            if label == 0:\n",
    "                # team classification\n",
    "                if kits_clf is not None and grass_hsv is not None:\n",
    "                    kit_color = get_kits_colors([result.orig_img[y1:y2, x1:x2]], grass_hsv)\n",
    "                    team = classify_kits(kits_clf, kit_color).item()\n",
    "                    label = 0 if team == left_team_label else 1\n",
    "\n",
    "                crop = result.orig_img[y1:y2, x1:x2]\n",
    "                h_c, w_c = crop.shape[:2]\n",
    "\n",
    "                num, conf, tag = None, 0.0, None\n",
    "                if h_c >= 55 and w_c >= 35:\n",
    "                    num, conf, tag = detect_jersey_number(crop, mode=JERSEY_MODE)\n",
    "                    update_track_number(track_id, num, conf)\n",
    "                    debug_info = (num, conf, tag, h_c, w_c)\n",
    "\n",
    "                # lock & keep\n",
    "                reads = track_numbers.get(track_id, [])\n",
    "                stable = get_stable_number(track_id)\n",
    "\n",
    "                if track_id is not None and track_id not in locked_number:\n",
    "                    if should_lock(track_id, stable, reads, prefer_two_digits=True):\n",
    "                        locked_number[track_id] = stable\n",
    "\n",
    "                maybe_upgrade_lock(track_id)\n",
    "\n",
    "                final_num = locked_number.get(track_id, None)\n",
    "                if final_num:\n",
    "                    jersey_text = f\"#{final_num}\"\n",
    "                else:\n",
    "                    if num is not None and conf >= SHOW_SINGLE_IF_CONF_GE:\n",
    "                        jersey_text = f\"#{num}\"\n",
    "\n",
    "                # DEBUG: save crops\n",
    "                if DEBUG_OCR and frame_idx <= DEBUG_MAX_FRAMES and track_id is not None:\n",
    "                    if frame_idx % DEBUG_SAVE_EVERY == 0:\n",
    "                        outp = os.path.join(DEBUG_DIR, f\"f{frame_idx:05d}_id{track_id}_hc{h_c}_wc{w_c}.jpg\")\n",
    "                        cv2.imwrite(outp, crop)\n",
    "\n",
    "            elif label == 1:\n",
    "                label = 2 if x1 < 0.5 * width else 3\n",
    "            else:\n",
    "                label = label + 2\n",
    "\n",
    "            # Draw box + label\n",
    "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), box_colors[str(label)], 2)\n",
    "            cv2.putText(\n",
    "                annotated_frame,\n",
    "                labels[label],\n",
    "                (x1 - 30, y1 - 10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.9,\n",
    "                box_colors[str(label)],\n",
    "                2\n",
    "            )\n",
    "\n",
    "            if jersey_text is not None:\n",
    "                cv2.putText(\n",
    "                    annotated_frame,\n",
    "                    jersey_text,\n",
    "                    (x1, y2 + 25),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.8,\n",
    "                    (255, 255, 255),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "            # Optional debug overlay\n",
    "            if DEBUG_OCR and debug_info is not None:\n",
    "                n, c, t, hc, wc = debug_info\n",
    "                txt = f\"\"\n",
    "                cv2.putText(\n",
    "                    annotated_frame,\n",
    "                    txt,\n",
    "                    (x1, y2 + 45),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.55,\n",
    "                    (0, 255, 255),\n",
    "                    2\n",
    "                )\n",
    "\n",
    "        cleanup_old_tracks(frame_idx)\n",
    "        output_video.write(annotated_frame)\n",
    "\n",
    "    pbar.close()\n",
    "    cv2.destroyAllWindows()\n",
    "    output_video.release()\n",
    "    cap.release()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ed66c",
   "metadata": {},
   "source": [
    "### ‚ñ∂Ô∏è Run Section\n",
    "##### Labels, Colors, Model Load, and Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "736997bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ultralytics\\nn\\tasks.py:732: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True | NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating video: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 743/744 [10:10<00:00,  1.22frame/s]\n"
     ]
    }
   ],
   "source": [
    "labels = [\"Player-L\", \"Player-R\", \"GK-L\", \"GK-R\", \"Ball\", \"Main Ref\", \"Side Ref\", \"Staff\"]\n",
    "box_colors = {\n",
    "    \"0\": (150, 50, 50),\n",
    "    \"1\": (37, 47, 150),\n",
    "    \"2\": (41, 248, 165),\n",
    "    \"3\": (166, 196, 10),\n",
    "    \"4\": (155, 62, 157),\n",
    "    \"5\": (123, 174, 213),\n",
    "    \"6\": (217, 89, 204),\n",
    "    \"7\": (22, 11, 15)\n",
    "}\n",
    "\n",
    "video_path = \"test_videos/CV_Task.mp4\"\n",
    "model = YOLO(\"weights/best.pt\")\n",
    "model.to(\"cuda:0\")\n",
    "\n",
    "print(\"CUDA:\", torch.cuda.is_available(), \"|\", torch.cuda.get_device_name(0))\n",
    "annotate_video(video_path, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
